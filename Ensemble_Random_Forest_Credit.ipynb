{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score, confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>defaulted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19394</td>\n",
       "      <td>19619</td>\n",
       "      <td>20024</td>\n",
       "      <td>2500</td>\n",
       "      <td>1815</td>\n",
       "      <td>657</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>542653</td>\n",
       "      <td>483003</td>\n",
       "      <td>473944</td>\n",
       "      <td>55000</td>\n",
       "      <td>40000</td>\n",
       "      <td>38000</td>\n",
       "      <td>20239</td>\n",
       "      <td>13750</td>\n",
       "      <td>13770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>100000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>221</td>\n",
       "      <td>-159</td>\n",
       "      <td>567</td>\n",
       "      <td>380</td>\n",
       "      <td>601</td>\n",
       "      <td>0</td>\n",
       "      <td>581</td>\n",
       "      <td>1687</td>\n",
       "      <td>1542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>140000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12211</td>\n",
       "      <td>11793</td>\n",
       "      <td>3719</td>\n",
       "      <td>3329</td>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13007</td>\n",
       "      <td>13912</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13007</td>\n",
       "      <td>1122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>200000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2513</td>\n",
       "      <td>1828</td>\n",
       "      <td>3731</td>\n",
       "      <td>2306</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>300</td>\n",
       "      <td>3738</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>260000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>8517</td>\n",
       "      <td>22287</td>\n",
       "      <td>13668</td>\n",
       "      <td>21818</td>\n",
       "      <td>9966</td>\n",
       "      <td>8583</td>\n",
       "      <td>22301</td>\n",
       "      <td>0</td>\n",
       "      <td>3640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>630000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>6500</td>\n",
       "      <td>6500</td>\n",
       "      <td>2870</td>\n",
       "      <td>1000</td>\n",
       "      <td>6500</td>\n",
       "      <td>6500</td>\n",
       "      <td>6500</td>\n",
       "      <td>2870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>70000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66782</td>\n",
       "      <td>36137</td>\n",
       "      <td>36894</td>\n",
       "      <td>3200</td>\n",
       "      <td>0</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>250000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>59696</td>\n",
       "      <td>56875</td>\n",
       "      <td>55512</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28771</td>\n",
       "      <td>29531</td>\n",
       "      <td>30211</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>1100</td>\n",
       "      <td>1200</td>\n",
       "      <td>1300</td>\n",
       "      <td>1100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>18338</td>\n",
       "      <td>17905</td>\n",
       "      <td>19104</td>\n",
       "      <td>3200</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>1650</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>320000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>70074</td>\n",
       "      <td>5856</td>\n",
       "      <td>195599</td>\n",
       "      <td>10358</td>\n",
       "      <td>10000</td>\n",
       "      <td>75940</td>\n",
       "      <td>20000</td>\n",
       "      <td>195599</td>\n",
       "      <td>50000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>360000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>180000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>130000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20616</td>\n",
       "      <td>11802</td>\n",
       "      <td>930</td>\n",
       "      <td>3000</td>\n",
       "      <td>1537</td>\n",
       "      <td>1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>930</td>\n",
       "      <td>33764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>632</td>\n",
       "      <td>316</td>\n",
       "      <td>316</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "      <td>632</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>70000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>44006</td>\n",
       "      <td>46905</td>\n",
       "      <td>46012</td>\n",
       "      <td>2007</td>\n",
       "      <td>3582</td>\n",
       "      <td>0</td>\n",
       "      <td>3601</td>\n",
       "      <td>0</td>\n",
       "      <td>1820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>450000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19428</td>\n",
       "      <td>1473</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>90000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>5398</td>\n",
       "      <td>6360</td>\n",
       "      <td>8292</td>\n",
       "      <td>5757</td>\n",
       "      <td>0</td>\n",
       "      <td>5398</td>\n",
       "      <td>1200</td>\n",
       "      <td>2045</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28967</td>\n",
       "      <td>29829</td>\n",
       "      <td>30046</td>\n",
       "      <td>1973</td>\n",
       "      <td>1426</td>\n",
       "      <td>1001</td>\n",
       "      <td>1432</td>\n",
       "      <td>1062</td>\n",
       "      <td>997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>60000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-57</td>\n",
       "      <td>127</td>\n",
       "      <td>-189</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>17878</td>\n",
       "      <td>18931</td>\n",
       "      <td>19617</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1000</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>2040</td>\n",
       "      <td>30430</td>\n",
       "      <td>257</td>\n",
       "      <td>3415</td>\n",
       "      <td>3421</td>\n",
       "      <td>2044</td>\n",
       "      <td>30430</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>17907</td>\n",
       "      <td>18375</td>\n",
       "      <td>11400</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29970</th>\n",
       "      <td>29971</td>\n",
       "      <td>360000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49005</td>\n",
       "      <td>8676</td>\n",
       "      <td>19487</td>\n",
       "      <td>52951</td>\n",
       "      <td>64535</td>\n",
       "      <td>8907</td>\n",
       "      <td>53</td>\n",
       "      <td>19584</td>\n",
       "      <td>16080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29971</th>\n",
       "      <td>29972</td>\n",
       "      <td>80000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>69674</td>\n",
       "      <td>71070</td>\n",
       "      <td>73612</td>\n",
       "      <td>2395</td>\n",
       "      <td>2500</td>\n",
       "      <td>2530</td>\n",
       "      <td>2556</td>\n",
       "      <td>3700</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29972</th>\n",
       "      <td>29973</td>\n",
       "      <td>190000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29223</td>\n",
       "      <td>19616</td>\n",
       "      <td>148482</td>\n",
       "      <td>2000</td>\n",
       "      <td>3869</td>\n",
       "      <td>25128</td>\n",
       "      <td>10115</td>\n",
       "      <td>148482</td>\n",
       "      <td>4800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29973</th>\n",
       "      <td>29974</td>\n",
       "      <td>230000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29974</th>\n",
       "      <td>29975</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2846</td>\n",
       "      <td>1585</td>\n",
       "      <td>1324</td>\n",
       "      <td>0</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29975</th>\n",
       "      <td>29976</td>\n",
       "      <td>220000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>5924</td>\n",
       "      <td>1759</td>\n",
       "      <td>1824</td>\n",
       "      <td>8840</td>\n",
       "      <td>6643</td>\n",
       "      <td>5924</td>\n",
       "      <td>1759</td>\n",
       "      <td>1824</td>\n",
       "      <td>7022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29976</th>\n",
       "      <td>29977</td>\n",
       "      <td>40000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>51259</td>\n",
       "      <td>47151</td>\n",
       "      <td>46934</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>3520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29977</th>\n",
       "      <td>29978</td>\n",
       "      <td>420000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>141695</td>\n",
       "      <td>144839</td>\n",
       "      <td>147954</td>\n",
       "      <td>7000</td>\n",
       "      <td>7000</td>\n",
       "      <td>5500</td>\n",
       "      <td>5500</td>\n",
       "      <td>5600</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29978</th>\n",
       "      <td>29979</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>219409</td>\n",
       "      <td>216540</td>\n",
       "      <td>210675</td>\n",
       "      <td>10029</td>\n",
       "      <td>9218</td>\n",
       "      <td>10029</td>\n",
       "      <td>8049</td>\n",
       "      <td>8040</td>\n",
       "      <td>10059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29979</th>\n",
       "      <td>29980</td>\n",
       "      <td>180000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29980</th>\n",
       "      <td>29981</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>50360</td>\n",
       "      <td>19971</td>\n",
       "      <td>19694</td>\n",
       "      <td>10000</td>\n",
       "      <td>4000</td>\n",
       "      <td>5000</td>\n",
       "      <td>3000</td>\n",
       "      <td>4500</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29981</th>\n",
       "      <td>29982</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>28192</td>\n",
       "      <td>22676</td>\n",
       "      <td>14647</td>\n",
       "      <td>2300</td>\n",
       "      <td>1700</td>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "      <td>503</td>\n",
       "      <td>585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29982</th>\n",
       "      <td>29983</td>\n",
       "      <td>90000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11328</td>\n",
       "      <td>12036</td>\n",
       "      <td>14329</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1200</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29983</th>\n",
       "      <td>29984</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>2882</td>\n",
       "      <td>9235</td>\n",
       "      <td>1719</td>\n",
       "      <td>2890</td>\n",
       "      <td>2720</td>\n",
       "      <td>2890</td>\n",
       "      <td>9263</td>\n",
       "      <td>1824</td>\n",
       "      <td>1701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29984</th>\n",
       "      <td>29985</td>\n",
       "      <td>30000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1993</td>\n",
       "      <td>1907</td>\n",
       "      <td>3319</td>\n",
       "      <td>923</td>\n",
       "      <td>2977</td>\n",
       "      <td>1999</td>\n",
       "      <td>3057</td>\n",
       "      <td>3319</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29985</th>\n",
       "      <td>29986</td>\n",
       "      <td>240000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29986</th>\n",
       "      <td>29987</td>\n",
       "      <td>360000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29987</th>\n",
       "      <td>29988</td>\n",
       "      <td>130000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>108047</td>\n",
       "      <td>93708</td>\n",
       "      <td>97353</td>\n",
       "      <td>3000</td>\n",
       "      <td>2000</td>\n",
       "      <td>93000</td>\n",
       "      <td>4000</td>\n",
       "      <td>5027</td>\n",
       "      <td>4005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29988</th>\n",
       "      <td>29989</td>\n",
       "      <td>250000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>245750</td>\n",
       "      <td>175005</td>\n",
       "      <td>179687</td>\n",
       "      <td>65000</td>\n",
       "      <td>8800</td>\n",
       "      <td>9011</td>\n",
       "      <td>6000</td>\n",
       "      <td>7000</td>\n",
       "      <td>6009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29989</th>\n",
       "      <td>29990</td>\n",
       "      <td>150000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>780</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9054</td>\n",
       "      <td>0</td>\n",
       "      <td>783</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29990</th>\n",
       "      <td>29991</td>\n",
       "      <td>140000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>138262</td>\n",
       "      <td>49675</td>\n",
       "      <td>46121</td>\n",
       "      <td>6000</td>\n",
       "      <td>7000</td>\n",
       "      <td>4228</td>\n",
       "      <td>1505</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29991</th>\n",
       "      <td>29992</td>\n",
       "      <td>210000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29992</th>\n",
       "      <td>29993</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29993</th>\n",
       "      <td>29994</td>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70626</td>\n",
       "      <td>69473</td>\n",
       "      <td>55004</td>\n",
       "      <td>2000</td>\n",
       "      <td>111784</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29994</th>\n",
       "      <td>29995</td>\n",
       "      <td>80000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>77519</td>\n",
       "      <td>82607</td>\n",
       "      <td>81158</td>\n",
       "      <td>7000</td>\n",
       "      <td>3500</td>\n",
       "      <td>0</td>\n",
       "      <td>7000</td>\n",
       "      <td>0</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>29996</td>\n",
       "      <td>220000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>88004</td>\n",
       "      <td>31237</td>\n",
       "      <td>15980</td>\n",
       "      <td>8500</td>\n",
       "      <td>20000</td>\n",
       "      <td>5003</td>\n",
       "      <td>3047</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>29997</td>\n",
       "      <td>150000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>8979</td>\n",
       "      <td>5190</td>\n",
       "      <td>0</td>\n",
       "      <td>1837</td>\n",
       "      <td>3526</td>\n",
       "      <td>8998</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>29998</td>\n",
       "      <td>30000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>20878</td>\n",
       "      <td>20582</td>\n",
       "      <td>19357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22000</td>\n",
       "      <td>4200</td>\n",
       "      <td>2000</td>\n",
       "      <td>3100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>29999</td>\n",
       "      <td>80000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52774</td>\n",
       "      <td>11855</td>\n",
       "      <td>48944</td>\n",
       "      <td>85900</td>\n",
       "      <td>3409</td>\n",
       "      <td>1178</td>\n",
       "      <td>1926</td>\n",
       "      <td>52964</td>\n",
       "      <td>1804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>30000</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36535</td>\n",
       "      <td>32428</td>\n",
       "      <td>15313</td>\n",
       "      <td>2078</td>\n",
       "      <td>1800</td>\n",
       "      <td>1430</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "0          1      20000    2          2         1   24      2      2     -1   \n",
       "1          2     120000    2          2         2   26     -1      2      0   \n",
       "2          3      90000    2          2         2   34      0      0      0   \n",
       "3          4      50000    2          2         1   37      0      0      0   \n",
       "4          5      50000    1          2         1   57     -1      0     -1   \n",
       "5          6      50000    1          1         2   37      0      0      0   \n",
       "6          7     500000    1          1         2   29      0      0      0   \n",
       "7          8     100000    2          2         2   23      0     -1     -1   \n",
       "8          9     140000    2          3         1   28      0      0      2   \n",
       "9         10      20000    1          3         2   35     -2     -2     -2   \n",
       "10        11     200000    2          3         2   34      0      0      2   \n",
       "11        12     260000    2          1         2   51     -1     -1     -1   \n",
       "12        13     630000    2          2         2   41     -1      0     -1   \n",
       "13        14      70000    1          2         2   30      1      2      2   \n",
       "14        15     250000    1          1         2   29      0      0      0   \n",
       "15        16      50000    2          3         3   23      1      2      0   \n",
       "16        17      20000    1          1         2   24      0      0      2   \n",
       "17        18     320000    1          1         1   49      0      0      0   \n",
       "18        19     360000    2          1         1   49      1     -2     -2   \n",
       "19        20     180000    2          1         2   29      1     -2     -2   \n",
       "20        21     130000    2          3         2   39      0      0      0   \n",
       "21        22     120000    2          2         1   39     -1     -1     -1   \n",
       "22        23      70000    2          2         2   26      2      0      0   \n",
       "23        24     450000    2          1         1   40     -2     -2     -2   \n",
       "24        25      90000    1          1         2   23      0      0      0   \n",
       "25        26      50000    1          3         2   23      0      0      0   \n",
       "26        27      60000    1          1         2   27      1     -2     -1   \n",
       "27        28      50000    2          3         2   30      0      0      0   \n",
       "28        29      50000    2          3         1   47     -1     -1     -1   \n",
       "29        30      50000    1          1         2   26      0      0      0   \n",
       "...      ...        ...  ...        ...       ...  ...    ...    ...    ...   \n",
       "29970  29971     360000    1          1         1   34     -1     -1     -1   \n",
       "29971  29972      80000    1          3         1   36      0      0      0   \n",
       "29972  29973     190000    1          1         1   37      0      0      0   \n",
       "29973  29974     230000    1          2         1   35      1     -2     -2   \n",
       "29974  29975      50000    1          2         1   37      1      2      2   \n",
       "29975  29976     220000    1          2         1   41      0      0     -1   \n",
       "29976  29977      40000    1          2         2   47      2      2      3   \n",
       "29977  29978     420000    1          1         2   34      0      0      0   \n",
       "29978  29979     310000    1          2         1   39      0      0      0   \n",
       "29979  29980     180000    1          1         1   32     -2     -2     -2   \n",
       "29980  29981      50000    1          3         2   42      0      0      0   \n",
       "29981  29982      50000    1          2         1   44      1      2      2   \n",
       "29982  29983      90000    1          2         1   36      0      0      0   \n",
       "29983  29984      20000    1          2         1   44     -2     -2     -2   \n",
       "29984  29985      30000    1          2         2   38     -1     -1     -2   \n",
       "29985  29986     240000    1          1         2   30     -2     -2     -2   \n",
       "29986  29987     360000    1          1         2   35     -1     -1     -2   \n",
       "29987  29988     130000    1          1         2   34      0      0      0   \n",
       "29988  29989     250000    1          1         1   34      0      0      0   \n",
       "29989  29990     150000    1          1         2   35     -1     -1     -1   \n",
       "29990  29991     140000    1          2         1   41      0      0      0   \n",
       "29991  29992     210000    1          2         1   34      3      2      2   \n",
       "29992  29993      10000    1          3         1   43      0      0      0   \n",
       "29993  29994     100000    1          1         2   38      0     -1     -1   \n",
       "29994  29995      80000    1          2         2   34      2      2      2   \n",
       "29995  29996     220000    1          3         1   39      0      0      0   \n",
       "29996  29997     150000    1          3         2   43     -1     -1     -1   \n",
       "29997  29998      30000    1          2         2   37      4      3      2   \n",
       "29998  29999      80000    1          3         1   41      1     -1      0   \n",
       "29999  30000      50000    1          2         1   46      0      0      0   \n",
       "\n",
       "       PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0         -1  ...          0          0          0         0       689   \n",
       "1          0  ...       3272       3455       3261         0      1000   \n",
       "2          0  ...      14331      14948      15549      1518      1500   \n",
       "3          0  ...      28314      28959      29547      2000      2019   \n",
       "4          0  ...      20940      19146      19131      2000     36681   \n",
       "5          0  ...      19394      19619      20024      2500      1815   \n",
       "6          0  ...     542653     483003     473944     55000     40000   \n",
       "7          0  ...        221       -159        567       380       601   \n",
       "8          0  ...      12211      11793       3719      3329         0   \n",
       "9         -2  ...          0      13007      13912         0         0   \n",
       "10         0  ...       2513       1828       3731      2306        12   \n",
       "11        -1  ...       8517      22287      13668     21818      9966   \n",
       "12        -1  ...       6500       6500       2870      1000      6500   \n",
       "13         0  ...      66782      36137      36894      3200         0   \n",
       "14         0  ...      59696      56875      55512      3000      3000   \n",
       "15         0  ...      28771      29531      30211         0      1500   \n",
       "16         2  ...      18338      17905      19104      3200         0   \n",
       "17        -1  ...      70074       5856     195599     10358     10000   \n",
       "18        -2  ...          0          0          0         0         0   \n",
       "19        -2  ...          0          0          0         0         0   \n",
       "20         0  ...      20616      11802        930      3000      1537   \n",
       "21        -1  ...          0        632        316       316       316   \n",
       "22         2  ...      44006      46905      46012      2007      3582   \n",
       "23        -2  ...        560          0          0     19428      1473   \n",
       "24        -1  ...       5398       6360       8292      5757         0   \n",
       "25         0  ...      28967      29829      30046      1973      1426   \n",
       "26        -1  ...        -57        127       -189         0      1000   \n",
       "27         0  ...      17878      18931      19617      1300      1300   \n",
       "28        -1  ...       2040      30430        257      3415      3421   \n",
       "29         0  ...      17907      18375      11400      1500      1500   \n",
       "...      ...  ...        ...        ...        ...       ...       ...   \n",
       "29970      0  ...      49005       8676      19487     52951     64535   \n",
       "29971      0  ...      69674      71070      73612      2395      2500   \n",
       "29972      0  ...      29223      19616     148482      2000      3869   \n",
       "29973     -2  ...          0          0          0         0         0   \n",
       "29974      2  ...       2846       1585       1324         0      3000   \n",
       "29975     -1  ...       5924       1759       1824      8840      6643   \n",
       "29976      2  ...      51259      47151      46934      4000         0   \n",
       "29977      0  ...     141695     144839     147954      7000      7000   \n",
       "29978      0  ...     219409     216540     210675     10029      9218   \n",
       "29979     -2  ...          0          0          0         0         0   \n",
       "29980      0  ...      50360      19971      19694     10000      4000   \n",
       "29981      2  ...      28192      22676      14647      2300      1700   \n",
       "29982      0  ...      11328      12036      14329      1500      1500   \n",
       "29983     -2  ...       2882       9235       1719      2890      2720   \n",
       "29984     -1  ...       1993       1907       3319       923      2977   \n",
       "29985     -2  ...          0          0          0         0         0   \n",
       "29986     -2  ...          0          0          0         0         0   \n",
       "29987      0  ...     108047      93708      97353      3000      2000   \n",
       "29988      0  ...     245750     175005     179687     65000      8800   \n",
       "29989     -1  ...        780          0          0      9054         0   \n",
       "29990      0  ...     138262      49675      46121      6000      7000   \n",
       "29991      2  ...       2500       2500       2500         0         0   \n",
       "29992     -2  ...          0          0          0      2000         0   \n",
       "29993      0  ...      70626      69473      55004      2000    111784   \n",
       "29994      2  ...      77519      82607      81158      7000      3500   \n",
       "29995      0  ...      88004      31237      15980      8500     20000   \n",
       "29996     -1  ...       8979       5190          0      1837      3526   \n",
       "29997     -1  ...      20878      20582      19357         0         0   \n",
       "29998      0  ...      52774      11855      48944     85900      3409   \n",
       "29999      0  ...      36535      32428      15313      2078      1800   \n",
       "\n",
       "       PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  defaulted  \n",
       "0             0         0         0         0          1  \n",
       "1          1000      1000         0      2000          1  \n",
       "2          1000      1000      1000      5000          0  \n",
       "3          1200      1100      1069      1000          0  \n",
       "4         10000      9000       689       679          0  \n",
       "5           657      1000      1000       800          0  \n",
       "6         38000     20239     13750     13770          0  \n",
       "7             0       581      1687      1542          0  \n",
       "8           432      1000      1000      1000          0  \n",
       "9             0     13007      1122         0          0  \n",
       "10           50       300      3738        66          0  \n",
       "11         8583     22301         0      3640          0  \n",
       "12         6500      6500      2870         0          0  \n",
       "13         3000      3000      1500         0          1  \n",
       "14         3000      3000      3000      3000          0  \n",
       "15         1100      1200      1300      1100          0  \n",
       "16         1500         0      1650         0          1  \n",
       "17        75940     20000    195599     50000          0  \n",
       "18            0         0         0         0          0  \n",
       "19            0         0         0         0          0  \n",
       "20         1000      2000       930     33764          0  \n",
       "21            0       632       316         0          1  \n",
       "22            0      3601         0      1820          1  \n",
       "23          560         0         0      1128          1  \n",
       "24         5398      1200      2045      2000          0  \n",
       "25         1001      1432      1062       997          0  \n",
       "26            0       500         0      1000          1  \n",
       "27         1000      1500      1000      1012          0  \n",
       "28         2044     30430       257         0          0  \n",
       "29         1000      1000      1600         0          0  \n",
       "...         ...       ...       ...       ...        ...  \n",
       "29970      8907        53     19584     16080          0  \n",
       "29971      2530      2556      3700      3000          0  \n",
       "29972     25128     10115    148482      4800          0  \n",
       "29973         0         0         0         0          1  \n",
       "29974         0         0      1000      1000          1  \n",
       "29975      5924      1759      1824      7022          0  \n",
       "29976      2000         0      3520         0          1  \n",
       "29977      5500      5500      5600      5000          0  \n",
       "29978     10029      8049      8040     10059          0  \n",
       "29979         0         0         0         0          0  \n",
       "29980      5000      3000      4500      2000          0  \n",
       "29981         0       517       503       585          0  \n",
       "29982      1500      1200      2500         0          1  \n",
       "29983      2890      9263      1824      1701          0  \n",
       "29984      1999      3057      3319      1000          0  \n",
       "29985         0         0         0         0          0  \n",
       "29986         0         0         0         0          0  \n",
       "29987     93000      4000      5027      4005          0  \n",
       "29988      9011      6000      7000      6009          0  \n",
       "29989       783         0         0         0          0  \n",
       "29990      4228      1505      2000      2000          0  \n",
       "29991         0         0         0         0          1  \n",
       "29992         0         0         0         0          0  \n",
       "29993      4000      3000      2000      2000          0  \n",
       "29994         0      7000         0      4000          1  \n",
       "29995      5003      3047      5000      1000          0  \n",
       "29996      8998       129         0         0          0  \n",
       "29997     22000      4200      2000      3100          1  \n",
       "29998      1178      1926     52964      1804          1  \n",
       "29999      1430      1000      1000      1000          1  \n",
       "\n",
       "[30000 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"credit-card-default.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "LIMIT_BAL    0\n",
       "SEX          0\n",
       "EDUCATION    0\n",
       "MARRIAGE     0\n",
       "AGE          0\n",
       "PAY_0        0\n",
       "PAY_2        0\n",
       "PAY_3        0\n",
       "PAY_4        0\n",
       "PAY_5        0\n",
       "PAY_6        0\n",
       "BILL_AMT1    0\n",
       "BILL_AMT2    0\n",
       "BILL_AMT3    0\n",
       "BILL_AMT4    0\n",
       "BILL_AMT5    0\n",
       "BILL_AMT6    0\n",
       "PAY_AMT1     0\n",
       "PAY_AMT2     0\n",
       "PAY_AMT3     0\n",
       "PAY_AMT4     0\n",
       "PAY_AMT5     0\n",
       "PAY_AMT6     0\n",
       "defaulted    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 24)\n",
      "(30000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Create dataframes for X and Y variables\n",
    "x = df.drop([\"defaulted\"], axis=1)\n",
    "y = df[['defaulted']]\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert x to dummy variables\n",
    "x=pd.get_dummies(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24000, 24), (6000, 24))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gini=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_gini = model_gini.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[3789  907]\n",
      " [ 752  552]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "mat_gini = confusion_matrix(y_test,preds_gini)\n",
    "\n",
    "print(\"confusion matrix = \\n\",mat_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7235\n"
     ]
    }
   ],
   "source": [
    "#Calculate accuracy\n",
    "\n",
    "print(accuracy_score(y_test,preds_gini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      4696\n",
      "           1       0.38      0.42      0.40      1304\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      6000\n",
      "   macro avg       0.61      0.62      0.61      6000\n",
      "weighted avg       0.74      0.72      0.73      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,preds_gini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=100,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pruned = DecisionTreeClassifier(criterion = \"gini\", random_state = 100,\n",
    "                               max_depth=5, min_samples_leaf=5)\n",
    "clf_pruned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_pruned = clf_pruned.predict(X_test)\n",
    "preds_pruned_train = clf_pruned.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[4441  255]\n",
      " [ 817  487]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "mat_pruned = confusion_matrix(y_test,preds_pruned)\n",
    "\n",
    "print(\"confusion matrix = \\n\",mat_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8213333333333334\n",
      "0.8235833333333333\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,preds_pruned))\n",
    "print(accuracy_score(y_train,preds_pruned_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      4696\n",
      "           1       0.66      0.37      0.48      1304\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      6000\n",
      "   macro avg       0.75      0.66      0.68      6000\n",
      "weighted avg       0.80      0.82      0.80      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,preds_pruned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat importance = [0.00036375 0.0008599  0.         0.0002329  0.         0.00017655\n",
      " 0.05220345 0.01044403 0.00080732 0.00153117 0.00093214 0.00145471\n",
      " 0.0012313  0.00015781 0.00022928 0.         0.         0.00015997\n",
      " 0.00023378 0.00383445 0.00066726 0.00028772 0.00015509 0.00019168]\n"
     ]
    }
   ],
   "source": [
    "feat_importance = clf_pruned.tree_.compute_feature_importances(normalize=False)\n",
    "print(\"feat importance = \" + str(feat_importance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#               Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first fit a random forest model with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importng random forest classifier from sklearn library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Running the random forest with default paarameters\n",
    "rfc=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit\n",
    "\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAking Predictions\n",
    "predictions=rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Classification report and confusion matrix from sklearn matrics\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.88      4696\n",
      "           1       0.61      0.35      0.44      1304\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      6000\n",
      "   macro avg       0.72      0.64      0.66      6000\n",
      "weighted avg       0.79      0.81      0.79      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# report of our default model\n",
    "\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8091666666666667\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good, let's now look at the list of hyperparameters which we can tune to improve model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# micro macro and weighted average\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                  Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_depth': range(2, 20, 5)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring='accuracy',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GridSearchCV to find optimal max_depth \n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#specify number of folds for k-fold CV\n",
    "n_folds=5\n",
    "\n",
    "#parameters to build the model on\n",
    "parameters={'max_depth':range(2,20,5)}\n",
    "\n",
    "#instantiate the model\n",
    "rf=RandomForestClassifier()\n",
    "\n",
    "#fit tree on training data\n",
    "rf=GridSearchCV(rf,parameters,cv=n_folds,scoring='accuracy')\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.281616</td>\n",
       "      <td>0.257264</td>\n",
       "      <td>0.014001</td>\n",
       "      <td>0.012001</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>0.797542</td>\n",
       "      <td>0.808790</td>\n",
       "      <td>0.804375</td>\n",
       "      <td>0.817879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805333</td>\n",
       "      <td>0.007530</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800458</td>\n",
       "      <td>0.807802</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.807041</td>\n",
       "      <td>0.801104</td>\n",
       "      <td>0.804448</td>\n",
       "      <td>0.003066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.348020</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.010801</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>0.808165</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.813750</td>\n",
       "      <td>0.828506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.817167</td>\n",
       "      <td>0.006691</td>\n",
       "      <td>1</td>\n",
       "      <td>0.832075</td>\n",
       "      <td>0.828949</td>\n",
       "      <td>0.832344</td>\n",
       "      <td>0.830321</td>\n",
       "      <td>0.830790</td>\n",
       "      <td>0.830896</td>\n",
       "      <td>0.001234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.529230</td>\n",
       "      <td>0.024344</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.024001</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 12}</td>\n",
       "      <td>0.809831</td>\n",
       "      <td>0.812539</td>\n",
       "      <td>0.814375</td>\n",
       "      <td>0.821213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814625</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>2</td>\n",
       "      <td>0.875931</td>\n",
       "      <td>0.878431</td>\n",
       "      <td>0.875417</td>\n",
       "      <td>0.875371</td>\n",
       "      <td>0.878496</td>\n",
       "      <td>0.876729</td>\n",
       "      <td>0.001430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.620636</td>\n",
       "      <td>0.011183</td>\n",
       "      <td>0.025401</td>\n",
       "      <td>0.020801</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_depth': 17}</td>\n",
       "      <td>0.800875</td>\n",
       "      <td>0.809206</td>\n",
       "      <td>0.803542</td>\n",
       "      <td>0.821838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809042</td>\n",
       "      <td>0.007228</td>\n",
       "      <td>3</td>\n",
       "      <td>0.919996</td>\n",
       "      <td>0.922392</td>\n",
       "      <td>0.918490</td>\n",
       "      <td>0.918494</td>\n",
       "      <td>0.922608</td>\n",
       "      <td>0.920396</td>\n",
       "      <td>0.001805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.281616      0.257264         0.014001        0.012001   \n",
       "1       0.348020      0.030300         0.010801        0.001166   \n",
       "2       0.529230      0.024344         0.025001        0.024001   \n",
       "3       0.620636      0.011183         0.025401        0.020801   \n",
       "\n",
       "  param_max_depth             params  split0_test_score  split1_test_score  \\\n",
       "0               2   {'max_depth': 2}           0.797542           0.808790   \n",
       "1               7   {'max_depth': 7}           0.808165           0.816705   \n",
       "2              12  {'max_depth': 12}           0.809831           0.812539   \n",
       "3              17  {'max_depth': 17}           0.800875           0.809206   \n",
       "\n",
       "   split2_test_score  split3_test_score  ...  mean_test_score  std_test_score  \\\n",
       "0           0.804375           0.817879  ...         0.805333        0.007530   \n",
       "1           0.813750           0.828506  ...         0.817167        0.006691   \n",
       "2           0.814375           0.821213  ...         0.814625        0.003771   \n",
       "3           0.803542           0.821838  ...         0.809042        0.007228   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                4            0.800458            0.807802   \n",
       "1                1            0.832075            0.828949   \n",
       "2                2            0.875931            0.878431   \n",
       "3                3            0.919996            0.922392   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.805833            0.807041            0.801104   \n",
       "1            0.832344            0.830321            0.830790   \n",
       "2            0.875417            0.875371            0.878496   \n",
       "3            0.918490            0.918494            0.922608   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.804448         0.003066  \n",
       "1          0.830896         0.001234  \n",
       "2          0.876729         0.001430  \n",
       "3          0.920396         0.001805  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scores of GridSearch CV\n",
    "\n",
    "scores=rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In above example, we can see that in k-fold cross-validation  ,k=5. and there are 4 levels for max_depth(2,7(5+2),12(7+5),17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting accuracies with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_depth\"],\n",
    "         scores[\"mean_train_score\"],\n",
    "        label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_depth\"],\n",
    "         scores[\"mean_test_score\"],\n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a model which performs well on test. We can see that highest accuracy of our test data is observed at depth=7 and hence,\n",
    "we choose that depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning n_estimators(default=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': range(100, 1500, 400)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GridSearchCV to find optimal n_estimators\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#specify number of folds for k-fold CV\n",
    "n_folds=5\n",
    "\n",
    "#parameters to build the model on\n",
    "parameters={'n_estimators':range(100,1500,400)}\n",
    "\n",
    "#instantiate the model\n",
    "rf=RandomForestClassifier(max_depth=4)           #can write 7 also\n",
    "\n",
    "#fit tree on training data\n",
    "rf=GridSearchCV(rf,parameters,cv=n_folds,scoring='accuracy')\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.998114</td>\n",
       "      <td>0.055277</td>\n",
       "      <td>0.061003</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>100</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "      <td>0.808790</td>\n",
       "      <td>0.813581</td>\n",
       "      <td>0.807500</td>\n",
       "      <td>0.820796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811583</td>\n",
       "      <td>0.005140</td>\n",
       "      <td>4</td>\n",
       "      <td>0.814209</td>\n",
       "      <td>0.813167</td>\n",
       "      <td>0.814844</td>\n",
       "      <td>0.812458</td>\n",
       "      <td>0.811937</td>\n",
       "      <td>0.813323</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.238386</td>\n",
       "      <td>0.806276</td>\n",
       "      <td>0.307418</td>\n",
       "      <td>0.021934</td>\n",
       "      <td>500</td>\n",
       "      <td>{'n_estimators': 500}</td>\n",
       "      <td>0.808582</td>\n",
       "      <td>0.813789</td>\n",
       "      <td>0.808542</td>\n",
       "      <td>0.818712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812000</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814001</td>\n",
       "      <td>0.812751</td>\n",
       "      <td>0.814167</td>\n",
       "      <td>0.811781</td>\n",
       "      <td>0.813395</td>\n",
       "      <td>0.813219</td>\n",
       "      <td>0.000875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.804018</td>\n",
       "      <td>0.231464</td>\n",
       "      <td>0.532230</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>900</td>\n",
       "      <td>{'n_estimators': 900}</td>\n",
       "      <td>0.808790</td>\n",
       "      <td>0.813997</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.818712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811917</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>2</td>\n",
       "      <td>0.813897</td>\n",
       "      <td>0.813167</td>\n",
       "      <td>0.814375</td>\n",
       "      <td>0.811364</td>\n",
       "      <td>0.813656</td>\n",
       "      <td>0.813292</td>\n",
       "      <td>0.001040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.151639</td>\n",
       "      <td>0.048113</td>\n",
       "      <td>0.755443</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>1300</td>\n",
       "      <td>{'n_estimators': 1300}</td>\n",
       "      <td>0.807957</td>\n",
       "      <td>0.813789</td>\n",
       "      <td>0.808542</td>\n",
       "      <td>0.818295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811875</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>3</td>\n",
       "      <td>0.814157</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>0.814167</td>\n",
       "      <td>0.811156</td>\n",
       "      <td>0.813395</td>\n",
       "      <td>0.813104</td>\n",
       "      <td>0.001125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.998114      0.055277         0.061003        0.001096   \n",
       "1      10.238386      0.806276         0.307418        0.021934   \n",
       "2      17.804018      0.231464         0.532230        0.008085   \n",
       "3      25.151639      0.048113         0.755443        0.002417   \n",
       "\n",
       "  param_n_estimators                  params  split0_test_score  \\\n",
       "0                100   {'n_estimators': 100}           0.808790   \n",
       "1                500   {'n_estimators': 500}           0.808582   \n",
       "2                900   {'n_estimators': 900}           0.808790   \n",
       "3               1300  {'n_estimators': 1300}           0.807957   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  ...  \\\n",
       "0           0.813581           0.807500           0.820796  ...   \n",
       "1           0.813789           0.808542           0.818712  ...   \n",
       "2           0.813997           0.808333           0.818712  ...   \n",
       "3           0.813789           0.808542           0.818295  ...   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.811583        0.005140                4            0.814209   \n",
       "1         0.812000        0.003861                1            0.814001   \n",
       "2         0.811917        0.003945                2            0.813897   \n",
       "3         0.811875        0.003808                3            0.814157   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.813167            0.814844            0.812458   \n",
       "1            0.812751            0.814167            0.811781   \n",
       "2            0.813167            0.814375            0.811364   \n",
       "3            0.812646            0.814167            0.811156   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.811937          0.813323         0.001076  \n",
       "1            0.813395          0.813219         0.000875  \n",
       "2            0.813656          0.813292         0.001040  \n",
       "3            0.813395          0.813104         0.001125  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scores of GridSearch CV\n",
    "\n",
    "scores=rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting accuracies with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_n_estimators\"],\n",
    "         scores[\"mean_train_score\"],\n",
    "        label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_n_estimators\"],\n",
    "         scores[\"mean_test_score\"],\n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get highest accuracy at n_estimators=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search to Find Optimal Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now find the optimal hyperparameters using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the parameter grid based on the results  of random search\n",
    "\n",
    "param_grid={\n",
    "    \n",
    "    'max_depth':[4,8,10],\n",
    "    'min_samples_leaf':range(100,400,200),\n",
    "    'min_samples_split':range(200,500,200),\n",
    "    'n_estimators': [5,10]\n",
    "    \n",
    "}\n",
    "\n",
    "#Create a based model\n",
    "rf=RandomForestClassifier()\n",
    "\n",
    "#Instantiate the grid search model\n",
    "\n",
    "grid_search=GridSearchCV(estimator=rf,param_grid=param_grid,cv=3,n_jobs=-1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:   38.8s finished\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_depth': [4, 8, 10], 'min_samples_leaf': range(100, 400, 200), 'min_samples_split': range(200, 500, 200), 'n_estimators': [5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the grid search to the data\n",
    "\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_jobs= -1 means use all the processors available in our computer . Usually python uses one processor(i3 has \n",
    "4 and i5 has 8 processors).n=-1 helps in faster execution \n",
    "                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of 0.8173333333333334 using {'max_depth': 8, 'min_samples_leaf': 100, 'min_samples_split': 200, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "#printing the optimal accuracy score and hyperparameters\n",
    "print('accuracy of',grid_search.best_score_,'using',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the final model with all best parameter values obtained from GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier(bootstrap=True,\n",
    "                           max_depth=8,\n",
    "                          min_samples_leaf=100, \n",
    "                           min_samples_split=200, \n",
    "                           n_estimators=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=100, min_samples_split=200,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "predictions=rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.818\n"
     ]
    }
   ],
   "source": [
    "#Calculate accuracy\n",
    "\n",
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
